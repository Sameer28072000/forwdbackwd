{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c6a99f-2a2e-4d20-adb4-b1f3830828c8",
   "metadata": {},
   "source": [
    "Q1. What is the purpose of forward propagation in a neural network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff316f-af1b-456a-a471-3ab7535ae6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:-During forward propagation, each neuron in the network receives input from the previous layer,\n",
    "       applies its activation function to compute its output.\n",
    "    Steps of forward propagation:\n",
    "        i.input\n",
    "          ii.weighted sum\n",
    "            iii.activation function \n",
    "               iv.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b1f479-4ff9-44a5-ac09-e70186109ba2",
   "metadata": {},
   "source": [
    "Q2. How is forward propagation implemented mathematically in a single-layer feedforward neural network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46d92d7-2e9e-4232-8733-463d79289e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:- The forward propagation in a single-layer feedforward neural network involves calculating the weighted sum\n",
    "          of the inputs applying an activation function to the sum, and obtaining the output of the neuron.\n",
    "      i.input\n",
    "        ii.weights & biases\n",
    "          ii.weighted sum\n",
    "            iii.activation function \n",
    "               iv.network output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fff2c4-21e3-4226-bc29-1f2fcda797db",
   "metadata": {},
   "source": [
    "Q3. How are activation functions used during forward propagation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439e8640-c2e0-4591-896b-70f4feb8de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:-\n",
    "     During forward propagation in a neural network, activation functions are applied to \n",
    "        the outputs of neurons to introduce non-linearity into the network .\n",
    "           determine the final output of each neuron. \n",
    "            \n",
    "        i.Sigmoid function\n",
    "          ii.ReLU (Rectified Linear Unit)\n",
    "            iii.Leaky ReLU\n",
    "              iv.softmax\n",
    "                 v.Hyperbolic Tangent(tanh)\n",
    "                    vi.Parametric ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f753ff20-44f7-4c37-90f9-ecd984b804d7",
   "metadata": {},
   "source": [
    "Q4. What is the role of weights and biases in forward propagation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d11e6ab-da7e-4177-934b-70f5f8a33814",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:-Weights and biases play a crucial role in forward propagation as they determine the input features &\n",
    "      provide a way to introduce flexibility and non-linearity into the neural network.\n",
    "    \n",
    "Weights: The weights in a neural network represent the strength or importance assigned to each input feature. \n",
    "    Biases: Biases are additional parameters associated with each neuron in the network,represented as a scalar value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646e513d-392c-47cf-bfb2-d728a6d33120",
   "metadata": {},
   "source": [
    "Q5. What is the purpose of applying a softmax function in the output layer during forward propagation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45616776-14a4-4a79-a1ff-a70263633aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:-The purpose of applying a softmax function in the output layer during forward propagation is to convert \n",
    "        the  raw outputs into a probability distribution.\n",
    "    \n",
    "    The softmax function is commonly used in multi-class classification problems where the goal is \n",
    "         to assign an input sample to one of several exclusive classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f022f-30b1-46fe-8ca9-c57db8d4bdc7",
   "metadata": {},
   "source": [
    "Q6. What is the purpose of backward propagation in a neural network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1b545f-4784-4c75-bfb5-d85d0f89fcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:-Backward propagation plays a crucial role in the training phase of a neural network.\n",
    "      \n",
    "    Steps of beckward propagation in neural network:\n",
    "        i.Loss calculation\n",
    "          ii.Gradient calculation\n",
    "            iii.Error back propagation\n",
    "              iv.Parameter update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087e2c2-e1e0-415b-8990-557895c9a900",
   "metadata": {},
   "source": [
    "Q7. How is backward propagation mathematically calculated in a single-layer feedforward neural network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b6187-0f93-4510-a88b-dc7884ee0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:-Backward propagation is mathematically calculated to update the weights and biases of the network based \n",
    "        on the gradients of the parameters with respect to the loss function.\n",
    "    \n",
    "    Steps of beckward propagation in neural network:\n",
    "        i.Loss calculation\n",
    "          ii.Gradient calculation\n",
    "            iii.Error back propagation\n",
    "              iv.Parameter update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eb0588-b6a8-4883-b9d3-fd0cfedd1351",
   "metadata": {},
   "source": [
    "Q8. Can you explain the concept of the chain rule and its application in backward propagation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7b3137-ffe9-437d-8c0a-091e8b602f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:-Mathematically, the chain rule can be expressed as follows:\n",
    "\n",
    "      (d/dx) [f(g(x))] = (df/dg) * (dg/dx)\n",
    "        By applying the chain rule iteratively for each layer in the network, we can efficiently\n",
    "             compute the gradients of the loss function with respect to the parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88080222-852d-444a-ae2d-3758f8f0efc4",
   "metadata": {},
   "source": [
    "Q9. What are some common challenges or issues that can occur during backward propagation, and how\n",
    "can they be addressed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f5aaf-1ab2-4e80-b00e-ee75ba9ae05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:-Common challenges or issues that can occur during backward propagation:\n",
    "       i.Vanishing gradient\n",
    "        i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
